# 社交媒体爬虫工具 - 项目概览

## 🎯 项目简介

这是一个功能完整的社交媒体爬虫桌面应用程序，可以爬取微博和抖音指定账号发布的帖子，并提供现代化的可视化界面进行管理和查看。

## ✨ 核心特性

### 1. 多平台支持
- ✅ **微博爬虫**: 完整实现，支持用户信息和帖子爬取
- ✅ **抖音爬虫**: 提供框架和模拟实现(真实爬取需配置)

### 2. 可视化界面
- 📝 **帖子列表页**: 表格展示所有帖子，支持筛选和搜索
- ⚙️ **任务管理页**: 配置和启动爬取任务，查看运行日志
- 🔧 **设置页**: 完善的配置管理系统

### 3. 数据管理
- 💾 **SQLite数据库**: 持久化存储用户和帖子数据
- 📊 **统计数据**: 点赞、评论、分享数量统计
- 🔍 **搜索过滤**: 支持关键词搜索和平台筛选

### 4. 系统功能
- ⏱️ **实时爬取**: 多线程异步爬取，不阻塞界面
- 📋 **日志记录**: 详细的运行日志和错误追踪
- ⚙️ **配置管理**: JSON配置文件，支持代理设置
- 📦 **打包支持**: 可打包为Windows独立可执行文件

## 📁 项目结构

```
coin_tool/
├── main.py                 # 主程序入口
├── config.py               # 全局配置管理
├── run.py                  # 开发运行脚本
├── requirements.txt        # Python依赖包
├── build.py                # PyInstaller打包脚本
├── build_spec.py           # spec文件生成脚本
├── install.bat             # Windows安装脚本
├── install.sh              # Linux/Mac安装脚本
├── test_import.py          # 模块导入测试脚本
├── 使用说明.md             # 详细使用文档
├── 项目概览.md             # 本文件
│
├── models/                 # 数据模型层
│   ├── __init__.py
│   └── database.py         # SQLite数据库操作
│       ├── Database类      # 数据库管理
│       ├── users表         # 用户信息
│       └── posts表         # 帖子信息
│
├── crawler/                # 爬虫层
│   ├── __init__.py
│   ├── base.py             # 爬虫基类(ABC)
│   ├── weibo_crawler.py    # 微博爬虫实现
│   ├── douyin_crawler.py   # 抖音爬虫实现
│   └── manager.py          # 爬虫管理器
│       ├── CrawlerThread   # 爬虫线程(QThread)
│       └── CrawlerManager  # 线程管理器
│
├── gui/                    # 界面层(PyQt5)
│   ├── __init__.py
│   ├── main_window.py      # 主窗口
│   ├── post_list.py        # 帖子列表组件
│   │   ├── PostListWidget      # 列表视图
│   │   └── PostDetailDialog    # 详情对话框
│   ├── task_panel.py       # 任务管理面板
│   └── config_panel.py     # 配置管理面板
│
├── utils/                  # 工具层
│   ├── __init__.py
│   └── logger.py           # 日志工具
│
├── data/                   # 数据目录(自动创建)
│   └── crawler.db          # SQLite数据库文件
│
├── logs/                   # 日志目录(自动创建)
│   └── crawler.log         # 运行日志
│
└── config/                 # 配置目录(自动创建)
    └── user_config.json    # 用户配置文件
```

## 🏗️ 技术架构

### 架构设计

采用**分层架构**设计，各层职责清晰:

```
┌─────────────────────────────────────┐
│         GUI Layer (PyQt5)           │
│  ┌──────────┐ ┌──────────┐ ┌─────┐ │
│  │PostList  │ │TaskPanel │ │Config│ │
│  └──────────┘ └──────────┘ └─────┘ │
└─────────────────────────────────────┘
                 ↓↑
┌─────────────────────────────────────┐
│      Business Logic Layer           │
│  ┌──────────────┐ ┌───────────────┐│
│  │CrawlerManager│ │ConfigManager  ││
│  └──────────────┘ └───────────────┘│
└─────────────────────────────────────┘
                 ↓↑
┌─────────────────────────────────────┐
│        Crawler Layer                │
│  ┌──────────┐ ┌──────────────────┐ │
│  │WeiboCrawl│ │DouyinCrawler     │ │
│  └──────────┘ └──────────────────┘ │
└─────────────────────────────────────┘
                 ↓↑
┌─────────────────────────────────────┐
│         Data Layer                  │
│         ┌────────────┐              │
│         │  Database  │              │
│         │  (SQLite)  │              │
│         └────────────┘              │
└─────────────────────────────────────┘
```

### 技术栈

| 技术 | 用途 | 版本 |
|------|------|------|
| Python | 编程语言 | 3.8+ |
| PyQt5 | GUI框架 | 5.15.10 |
| SQLite | 数据库 | 内置 |
| requests | HTTP请求 | 2.31.0 |
| PyInstaller | 打包工具 | 6.3.0 |

### 核心类说明

#### 1. Database (models/database.py)
- 数据库连接管理
- 用户和帖子的CRUD操作
- 上下文管理器模式

#### 2. BaseCrawler (crawler/base.py)
- 抽象基类，定义爬虫接口
- `get_user_info()`: 获取用户信息
- `get_user_posts()`: 获取用户帖子列表

#### 3. CrawlerThread (crawler/manager.py)
- 继承QThread，异步执行爬虫任务
- 发送进度、错误、完成信号
- 支持停止操作

#### 4. MainWindow (gui/main_window.py)
- 主窗口，包含三个标签页
- 定时刷新机制
- 信号槽连接管理

## 🚀 快速开始

### 1. 安装依赖

**Windows:**
```bash
install.bat
```

**Mac/Linux:**
```bash
chmod +x install.sh
./install.sh
```

### 2. 运行程序

```bash
python run.py
```

### 3. 使用流程

1. 启动程序
2. 切换到"任务管理"标签
3. 选择平台，输入用户ID
4. 点击"开始爬取"
5. 在"帖子列表"查看结果

## 📦 打包发布

### 打包为Windows可执行文件

```bash
# 方法1: 使用打包脚本
python build.py

# 方法2: 使用spec文件
python build_spec.py
pyinstaller crawler.spec
```

打包后的文件在 `dist/` 目录。

## 🔧 配置说明

配置文件: `config/user_config.json`

```json
{
  "weibo": {
    "enabled": true,
    "users": [],
    "interval": 300,
    "max_posts": 50
  },
  "douyin": {
    "enabled": true,
    "users": [],
    "interval": 300,
    "max_posts": 50
  },
  "proxy": {
    "enabled": false,
    "http": "",
    "https": ""
  },
  "notification": {
    "enabled": true,
    "sound": true
  }
}
```

## 📊 数据库结构

### users 表

| 字段 | 类型 | 说明 |
|------|------|------|
| id | INTEGER | 主键 |
| platform | TEXT | 平台(weibo/douyin) |
| user_id | TEXT | 用户ID |
| username | TEXT | 用户名 |
| avatar | TEXT | 头像URL |
| description | TEXT | 简介 |
| followers | INTEGER | 粉丝数 |
| created_at | TIMESTAMP | 创建时间 |
| updated_at | TIMESTAMP | 更新时间 |

### posts 表

| 字段 | 类型 | 说明 |
|------|------|------|
| id | INTEGER | 主键 |
| platform | TEXT | 平台 |
| post_id | TEXT | 帖子ID |
| user_id | TEXT | 用户ID |
| username | TEXT | 用户名 |
| content | TEXT | 内容 |
| images | TEXT | 图片(JSON数组) |
| videos | TEXT | 视频(JSON数组) |
| likes | INTEGER | 点赞数 |
| comments | INTEGER | 评论数 |
| shares | INTEGER | 分享数 |
| post_url | TEXT | 帖子链接 |
| published_at | TIMESTAMP | 发布时间 |
| created_at | TIMESTAMP | 创建时间 |
| updated_at | TIMESTAMP | 更新时间 |

## 🎨 界面截图说明

### 帖子列表页
- 表格显示所有帖子
- 顶部筛选栏(平台、搜索)
- 底部统计信息
- 双击查看详情

### 任务管理页
- 左侧: 添加任务表单
- 左侧下方: 已配置用户列表
- 右侧: 运行日志窗口

### 设置页
- 微博配置组
- 抖音配置组
- 代理配置组
- 通知配置组
- 保存/重置按钮

## ⚠️ 注意事项

1. **微博爬虫**: 
   - 使用移动端API，较为稳定
   - 支持用户名转UID
   - 建议设置合理的爬取间隔

2. **抖音爬虫**: 
   - 默认使用模拟数据
   - 真实爬取需要配置cookie和签名
   - 反爬机制较强，建议使用API

3. **法律合规**: 
   - 仅供学习研究使用
   - 遵守平台使用条款
   - 不要爬取敏感信息

4. **性能优化**: 
   - 使用线程池管理并发
   - 数据库批量操作
   - 合理设置缓存

## 🔮 未来规划

- [ ] 自动定时任务
- [ ] 更多平台支持(知乎、B站等)
- [ ] 数据导出功能(Excel、CSV)
- [ ] 数据可视化图表
- [ ] 关键词监控和通知
- [ ] 云端备份
- [ ] 移动端APP

## 📝 开发日志

### v1.0.0 (2026-01-19)
- ✅ 完整的项目架构
- ✅ 微博爬虫实现
- ✅ 抖音爬虫框架
- ✅ PyQt5界面开发
- ✅ 数据库设计和实现
- ✅ 配置管理系统
- ✅ 日志系统
- ✅ 打包脚本
- ✅ 完整文档

## 🤝 贡献指南

欢迎提交Issue和Pull Request！

## 📄 许可证

本项目仅供学习和研究使用。

---

**开发者**: CoinTool Team  
**版本**: v1.0.0  
**日期**: 2026-01-19
